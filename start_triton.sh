#!/bin/bash

echo "üöÄ –ó–∞–ø—É—Å–∫ Triton Inference Server"

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
if [ ! -f "triton/models/ai_classifier/1/model.onnx" ]; then
    echo "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ triton/models/ai_classifier/1/model.onnx"
    echo "   –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤—å: python prepare_triton.py"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥
if [ ! -f "triton/models/ai_classifier/config.pbtxt" ]; then
    echo "‚ùå –ö–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω"
    exit 1
fi

echo "‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞: $(ls -la triton/models/ai_classifier/1/model.onnx)"

# –ó–∞–ø—É—Å–∫–∞–µ–º Triton —Å –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π
echo "üê≥ –ó–∞–ø—É—Å–∫ Triton –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞–∑–∞..."
echo "üìÅ –ú–æ–¥–µ–ª–∏ –º–æ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –∏–∑: $(pwd)/triton/models"

docker run \
    --rm \
    -p 8000:8000 \
    -p 8001:8001 \
    -p 8002:8002 \
    -v $(pwd)/triton/models:/models \
    nvcr.io/nvidia/tritonserver:25.12-py3 \
    tritonserver \
    --model-repository=/models \
    --strict-model-config=false \
    --log-verbose=1