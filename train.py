"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ò–ò-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–° –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Hydra –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
"""

import os
import sys
import random
from pathlib import Path

# –û—Ç–∫–ª—é—á–∞–µ–º triton –Ω–∞ Windows (–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
if os.name == "nt":  # Windows
    os.environ.setdefault("TORCH_COMPILE_DISABLE", "1")
    os.environ.setdefault("TORCHDYNAMO_DISABLE", "1")
    sys.stdout.reconfigure(encoding="utf-8")
    sys.stderr.reconfigure(encoding="utf-8")

import hydra
import lightning as L
import mlflow
import numpy as np
import torch
from omegaconf import DictConfig, OmegaConf
from lightning.pytorch.loggers import MLFlowLogger

from src.ai_images_classifier.modules.data_module import AIImageDataModule
from src.ai_images_classifier.modules.lightning_module import AIImageClassifierModule
from src.ai_images_classifier.utils.metrics_collector import MetricsCollectorCallback
from src.ai_images_classifier.utils.mlflow_utils import log_hyperparameters_to_mlflow


def set_seed(seed: int):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


@hydra.main(
    version_base=None,
    config_path="conf",
    config_name="config",
)
def main(cfg: DictConfig) -> None:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è

    Args:
        cfg: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ Hydra
    """
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed
    if hasattr(cfg, "seed"):
        set_seed(cfg.seed)
        print(f"Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {cfg.seed}")

    # –í—ã–≤–æ–¥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:")
    print(OmegaConf.to_yaml(cfg))

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–º–æ—Ä–æ–∑–∫–µ
    if hasattr(cfg.model, "freeze_backbone") and cfg.model.freeze_backbone:
        print("üßä Backbone –ë–£–î–ï–¢ –ó–ê–ú–û–†–û–ñ–ï–ù –Ω–∞ –≤—Å—ë –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è")
        print("   (–æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä)")
    else:
        print("üî• Backbone –ù–ï –∑–∞–º–æ—Ä–æ–∂–µ–Ω")
        print("   (–æ–±—É—á–∞–µ—Ç—Å—è –≤—Å—è –º–æ–¥–µ–ª—å)")

    print("=" * 60 + "\n")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataModule
    data_module = AIImageDataModule(
        data_dir=cfg.data.data_dir,
        batch_size=cfg.data.batch_size,
        num_workers=cfg.data.num_workers,
        image_size=cfg.data.image_size,
        train_split=cfg.data.train_split,
        val_split=cfg.data.val_split,
        test_split=cfg.data.test_split,
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    print("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
    model = AIImageClassifierModule(
        backbone_name=cfg.model.backbone_name,
        num_classes=cfg.model.num_classes,
        dropout=cfg.model.dropout,
        learning_rate=cfg.training.learning_rate,
        weight_decay=cfg.training.weight_decay,
        pretrained=cfg.model.pretrained,
        freeze_backbone=cfg.model.get("freeze_backbone", False),
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ callbacks –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    callbacks = []

    # ModelCheckpoint
    if "checkpoint" in cfg.callbacks:
        checkpoint_callback = hydra.utils.instantiate(cfg.callbacks.checkpoint)
        callbacks.append(checkpoint_callback)

    # EarlyStopping
    if "early_stopping" in cfg.callbacks:
        early_stopping = hydra.utils.instantiate(cfg.callbacks.early_stopping)
        callbacks.append(early_stopping)

    # LearningRateMonitor
    if "lr_monitor" in cfg.callbacks:
        lr_monitor = hydra.utils.instantiate(cfg.callbacks.lr_monitor)
        callbacks.append(lr_monitor)

    # MetricsCollector –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    metrics_collector = MetricsCollectorCallback(plots_dir=Path("plots"))
    callbacks.append(metrics_collector)

    # –°–æ–∑–¥–∞–Ω–∏–µ logger –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    logger = None
    mlflow_logger = None
    if "logger" in cfg and cfg.logger is not None:
        logger_config = cfg.logger.copy()
        # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ logger
        if "name" in logger_config:
            logger_config.name = cfg.experiment_name
        logger = hydra.utils.instantiate(logger_config)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ logger MLflowLogger
        if isinstance(logger, MLFlowLogger):
            mlflow_logger = logger
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MLflow run
            tracking_uri = cfg.logger.get("tracking_uri") or cfg.get("mlflow", {}).get("tracking_uri", "http://127.0.0.1:8080")
            mlflow.set_tracking_uri(tracking_uri)
            mlflow.set_experiment(cfg.logger.experiment_name)
            try:
                mlflow.start_run()
                # –õ–æ–≥–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ git commit id
                log_hyperparameters_to_mlflow(cfg)
            except Exception as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MLflow —Å–µ—Ä–≤–µ—Ä—É: {e}")
                print("   –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—Å—è –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ MLflow")
                mlflow_logger = None

    # Trainer
    trainer = L.Trainer(
        max_epochs=cfg.training.max_epochs,
        accelerator=cfg.lightning.accelerator,
        devices=cfg.lightning.devices,
        precision=cfg.lightning.precision,
        callbacks=callbacks,
        logger=logger,
        log_every_n_steps=cfg.lightning.log_every_n_steps,
        val_check_interval=cfg.lightning.val_check_interval,
        enable_progress_bar=cfg.lightning.enable_progress_bar,
        enable_model_summary=cfg.lightning.enable_model_summary,
    )

    # –û–±—É—á–µ–Ω–∏–µ
    print("\n" + "=" * 50)
    print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è")
    print("=" * 50 + "\n")
    trainer.fit(model, data_module)

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\n" + "=" * 50)
    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    print("=" * 50 + "\n")
    trainer.test(model, data_module)

    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if "checkpoint" in cfg.callbacks and hasattr(
        checkpoint_callback, "best_model_path"
    ):
        print(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {checkpoint_callback.best_model_path}")

    # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ MLflow
    if mlflow_logger is not None:
        try:
            # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ callback_metrics
            if hasattr(trainer, "callback_metrics"):
                for metric_name, metric_value in trainer.callback_metrics.items():
                    if isinstance(metric_value, torch.Tensor):
                        mlflow.log_metric(metric_name, metric_value.item())
                    elif isinstance(metric_value, (int, float)):
                        mlflow.log_metric(metric_name, metric_value)

            print("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã –≤ MLflow")
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ MLflow: {e}")

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º MLflow run
    if mlflow_logger is not None:
        mlflow.end_run()


if __name__ == "__main__":
    main()
