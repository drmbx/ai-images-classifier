"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ò–ò-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–° –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Hydra –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
"""

import random

import hydra
import lightning as L
import numpy as np
import torch
from omegaconf import DictConfig, OmegaConf

from src.ai_images_classifier.modules.data_module import AIImageDataModule
from src.ai_images_classifier.modules.lightning_module import AIImageClassifierModule


def set_seed(seed: int):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


@hydra.main(
    version_base=None,
    config_path="conf",
    config_name="config",
)
def main(cfg: DictConfig) -> None:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è

    Args:
        cfg: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ Hydra
    """
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed
    if hasattr(cfg, "seed"):
        set_seed(cfg.seed)
        print(f"Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {cfg.seed}")

    # –í—ã–≤–æ–¥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:")
    print(OmegaConf.to_yaml(cfg))

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–º–æ—Ä–æ–∑–∫–µ
    if hasattr(cfg.model, "freeze_backbone") and cfg.model.freeze_backbone:
        print("üßä Backbone –ë–£–î–ï–¢ –ó–ê–ú–û–†–û–ñ–ï–ù –Ω–∞ –≤—Å—ë –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è")
        print("   (–æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä)")
    else:
        print("üî• Backbone –ù–ï –∑–∞–º–æ—Ä–æ–∂–µ–Ω")
        print("   (–æ–±—É—á–∞–µ—Ç—Å—è –≤—Å—è –º–æ–¥–µ–ª—å)")

    print("=" * 60 + "\n")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataModule
    data_module = AIImageDataModule(
        data_dir=cfg.data.data_dir,
        batch_size=cfg.data.batch_size,
        num_workers=cfg.data.num_workers,
        image_size=cfg.data.image_size,
        train_split=cfg.data.train_split,
        val_split=cfg.data.val_split,
        test_split=cfg.data.test_split,
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    print("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
    model = AIImageClassifierModule(
        backbone_name=cfg.model.backbone_name,
        num_classes=cfg.model.num_classes,
        dropout=cfg.model.dropout,
        learning_rate=cfg.training.learning_rate,
        weight_decay=cfg.training.weight_decay,
        pretrained=cfg.model.pretrained,
        freeze_backbone=cfg.model.get("freeze_backbone", False),
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ callbacks –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    callbacks = []

    # ModelCheckpoint
    if "checkpoint" in cfg.callbacks:
        checkpoint_callback = hydra.utils.instantiate(cfg.callbacks.checkpoint)
        callbacks.append(checkpoint_callback)

    # EarlyStopping
    if "early_stopping" in cfg.callbacks:
        early_stopping = hydra.utils.instantiate(cfg.callbacks.early_stopping)
        callbacks.append(early_stopping)

    # LearningRateMonitor
    if "lr_monitor" in cfg.callbacks:
        lr_monitor = hydra.utils.instantiate(cfg.callbacks.lr_monitor)
        callbacks.append(lr_monitor)

    # –°–æ–∑–¥–∞–Ω–∏–µ logger –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    logger = None
    if "logger" in cfg and cfg.logger is not None:
        logger_config = cfg.logger.copy()
        # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ logger
        if "name" in logger_config:
            logger_config.name = cfg.experiment_name
        logger = hydra.utils.instantiate(logger_config)

    # Trainer
    trainer = L.Trainer(
        max_epochs=cfg.training.max_epochs,
        accelerator=cfg.lightning.accelerator,
        devices=cfg.lightning.devices,
        precision=cfg.lightning.precision,
        callbacks=callbacks,
        logger=logger,
        log_every_n_steps=cfg.lightning.log_every_n_steps,
        val_check_interval=cfg.lightning.val_check_interval,
        enable_progress_bar=cfg.lightning.enable_progress_bar,
        enable_model_summary=cfg.lightning.enable_model_summary,
    )

    # –û–±—É—á–µ–Ω–∏–µ
    print("\n" + "=" * 50)
    print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è")
    print("=" * 50 + "\n")
    trainer.fit(model, data_module)

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\n" + "=" * 50)
    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    print("=" * 50 + "\n")
    trainer.test(model, data_module)

    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if "checkpoint" in cfg.callbacks and hasattr(
        checkpoint_callback, "best_model_path"
    ):
        print(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {checkpoint_callback.best_model_path}")


if __name__ == "__main__":
    main()
