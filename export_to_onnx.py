"""
–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX —Ñ–æ—Ä–º–∞—Ç
"""

import argparse
import os
import shutil
import sys
from pathlib import Path

import onnx
import torch

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.ai_images_classifier.modules.lightning_module import AIImageClassifierModule


def export_to_onnx(model_path, output_path, image_size=224, opset_version=18):
    """
    –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX —Ñ–æ—Ä–º–∞—Ç

    Args:
        model_path: –ü—É—Ç—å –∫ checkpoint PyTorch Lightning
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ONNX –º–æ–¥–µ–ª–∏
        image_size: –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        opset_version: –í–µ—Ä—Å–∏—è ONNX opset
    """
    print("üîÑ –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX...")

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ—Ç
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ checkpoint
    print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
    pl_model = AIImageClassifierModule.load_from_checkpoint(model_path)
    model = pl_model.model
    model.eval()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞:")
    print(f"   - Backbone: {model.backbone_name}")
    print(f"   - –ö–ª–∞—Å—Å—ã: {model.num_classes}")
    print(f"   - Freeze backbone: {model.freeze_backbone}")

    # –°–æ–∑–¥–∞–µ–º dummy input
    batch_size = 1
    dummy_input = torch.randn(batch_size, 3, image_size, image_size)

    # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
    print("\nüì§ –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX...")
    print(f"   Input shape: {dummy_input.shape}")
    print(f"   Output path: {output_path}")
    print(f"   Opset version: {opset_version}")

    # –í—Ö–æ–¥–Ω—ã–µ –∏ –≤—ã—Ö–æ–¥–Ω—ã–µ –∏–º–µ–Ω–∞
    input_names = ["input_image"]
    output_names = ["output_logits"]

    # –≠–∫—Å–ø–æ—Ä—Ç
    torch.onnx.export(
        model,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=opset_version,
        do_constant_folding=True,
        input_names=input_names,
        output_names=output_names,
        verbose=False,
        external_data=False,
    )

    print(f"\n‚úÖ ONNX –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    try:
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        input_info = onnx_model.graph.input[0]
        output_info = onnx_model.graph.output[0]

        print("\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ ONNX –º–æ–¥–µ–ª–∏:")
        print(f"   Input:  {input_info.name}")
        print(f"   Output: {output_info.name}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π opset
        if onnx_model.opset_import:
            for opset in onnx_model.opset_import:
                if opset.domain == "":
                    print(f"   Opset version: {opset.version}")

        print(f"   –û–ø–µ—Ä–∞—Ü–∏–π: {len(onnx_model.graph.node)}")
        print(f"   –†–∞–∑–º–µ—Ä: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")

    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ ONNX: {e}")

    return output_path


def main():
    parser = argparse.ArgumentParser(description="–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX")
    parser.add_argument(
        "--model_path", type=str, required=True, help="–ü—É—Ç—å –∫ checkpoint –º–æ–¥–µ–ª–∏ (.ckpt)"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="models/onnx",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ONNX –º–æ–¥–µ–ª–∏",
    )
    parser.add_argument(
        "--image_size", type=int, default=224, help="–†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
    )
    parser.add_argument("--opset", type=int, default=18, help="ONNX opset version")
    parser.add_argument(
        "--copy_to_triton",
        action="store_true",
        help="–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤ Triton –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é",
    )

    args = parser.parse_args()

    # –ò–º—è —Ñ–∞–π–ª–∞
    model_name = Path(args.model_path).stem
    output_path = Path(args.output_dir) / f"{model_name}.onnx"

    # –≠–∫—Å–ø–æ—Ä—Ç
    onnx_path = export_to_onnx(
        model_path=args.model_path,
        output_path=str(output_path),
        image_size=args.image_size,
        opset_version=args.opset,
    )

    # –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ triton –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.copy_to_triton:
        triton_onnx_path = Path("triton/models/ai_classifier/1/model.onnx")
        triton_onnx_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy(onnx_path, triton_onnx_path)
        print(f"\nüìÅ –ú–æ–¥–µ–ª—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è Triton: {triton_onnx_path}")


if __name__ == "__main__":
    main()
