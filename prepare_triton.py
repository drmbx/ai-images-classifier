"""
–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è Triton
"""

import shutil
import sys
from pathlib import Path

# –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π checkpoint
checkpoints = list(Path("checkpoints").glob("*.ckpt"))
if not checkpoints:
    print("‚ùå –ù–µ—Ç checkpoint —Ñ–∞–π–ª–æ–≤")
    sys.exit(1)

latest_checkpoint = sorted(checkpoints)[-1]
print(f"üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ–º checkpoint: {latest_checkpoint}")

# –ò—â–µ–º ONNX –º–æ–¥–µ–ª—å
onnx_files = list(Path("models/onnx").glob("*.onnx"))
if not onnx_files:
    print("‚ùå –ù–µ—Ç ONNX –º–æ–¥–µ–ª–µ–π. –°–Ω–∞—á–∞–ª–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π:")
    print("   python export_to_onnx.py --model_path checkpoints/best-model.ckpt")
    sys.exit(1)

latest_onnx = sorted(onnx_files)[-1]

# –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
model_dir = Path("triton/models/ai_classifier/1")
model_dir.mkdir(parents=True, exist_ok=True)

# –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
shutil.copy(latest_onnx, model_dir / "model.onnx")
print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –≤: {model_dir}/model.onnx")

# –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –µ—Å–ª–∏ –Ω–µ—Ç
config_file = Path("triton/models/ai_classifier/config.pbtxt")
if not config_file.exists():
    config_file.parent.mkdir(parents=True, exist_ok=True)

    config = """name: "ai_classifier"
platform: "onnxruntime_onnx"
max_batch_size: 32

input [
  {
    name: "input_image"
    data_type: TYPE_FP32
    dims: [ 3, 224, 224 ]
  }
]

output [
  {
    name: "output_logits"
    data_type: TYPE_FP32
    dims: [ 2 ]
  }
]

instance_group [
  {
    count: 1
    kind: KIND_CPU
  }
]

dynamic_batching {
  max_queue_delay_microseconds: 100
}
"""

    with open(config_file, "w") as f:
        f.write(config)

    print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥ —Å–æ–∑–¥–∞–Ω: {config_file}")

print("‚úÖ Triton –º–æ–¥–µ–ª—å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞!")
